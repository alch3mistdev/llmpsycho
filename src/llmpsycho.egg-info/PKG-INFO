Metadata-Version: 2.4
Name: llmpsycho
Version: 0.1.0
Summary: Adaptive low-cost psychometric profiling for LLMs
Author: llmpsycho
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Provides-Extra: anthropic
Requires-Dist: anthropic>=0.39; extra == "anthropic"
Provides-Extra: openai
Requires-Dist: openai>=1.0; extra == "openai"
Provides-Extra: studio
Requires-Dist: fastapi>=0.115; extra == "studio"
Requires-Dist: uvicorn>=0.30; extra == "studio"
Requires-Dist: pydantic>=2.7; extra == "studio"
Requires-Dist: python-multipart>=0.0.9; extra == "studio"
Requires-Dist: jsonschema>=4.22; extra == "studio"
Provides-Extra: all
Requires-Dist: anthropic>=0.39; extra == "all"
Requires-Dist: openai>=1.0; extra == "all"
Requires-Dist: fastapi>=0.115; extra == "all"
Requires-Dist: uvicorn>=0.30; extra == "all"
Requires-Dist: pydantic>=2.7; extra == "all"
Requires-Dist: python-multipart>=0.0.9; extra == "all"
Requires-Dist: jsonschema>=4.22; extra == "all"

# llmpsycho

Convergence-first adaptive psychometric profiling for LLMs over chat-completions APIs, plus an interactive Profile Studio and Query Lab.

## Core profiling engine

Implemented in `src/adaptive_profiler`:

- 12-trait latent profile (`T1..T12`) across capability + alignment behavior.
- Multidimensional 2PL-style Bayesian updater.
- Adaptive selection with coverage + sentinel/OOD robustness controls.
- Convergence-first defaults:
  - `call_cap=60`
  - `token_cap=14000`
  - `min_calls_before_global_stop=40`
  - `min_items_per_critical_trait=6`
  - critical traits: `T4,T5,T8,T9,T10`
- Two-regime operation (`core`, `safety`) and JSON schema output.

## Profile Studio (FastAPI + React)

Profile Studio provides:

- Profile run creation with live event stream (`SSE`) telemetry.
- Profile history explorer with detailed trait/risk views.
- Ingestion center with watched-folder sync and manual file import.
- Query Lab with same-model A/B intervention (`profile off` vs `profile on`).

### Backend API

Code: `src/profile_studio_api`

Run locally:

```bash
pip install -e ".[studio]"
uvicorn profile_studio_api.main:app --reload
```

Default API URL: `http://localhost:8000`

### Frontend UX

Code: `web/`

Run locally:

```bash
cd web
npm install
npm run dev
```

Default UI URL: `http://localhost:5173`

## Data directories

Created automatically by backend startup:

- `data/profile_store.sqlite`: SQLite index/history store.
- `data/profiles/*.json`: canonical profile artifacts.
- `data/ingestion/`: watched ingestion folder.
- `data/quarantine/`: invalid ingestion payload copies.

## API surface

- `POST /api/runs`
- `GET /api/runs/{run_id}`
- `GET /api/runs/{run_id}/events`
- `GET /api/profiles`
- `GET /api/profiles/{profile_id}`
- `POST /api/profiles/import`
- `POST /api/ingestion/scan`
- `GET /api/ingestion/status`
- `POST /api/query-lab/ab`
- `POST /api/query-lab/apply`
- `GET /api/meta/models`

## Provider setup (real model calls)

Install optional provider dependencies:

```bash
pip install -e ".[openai]"
pip install -e ".[anthropic]"
# or both + studio
pip install -e ".[all]"
```

Set API keys:

```bash
export OPENAI_API_KEY="sk-..."
export ANTHROPIC_API_KEY="sk-ant-..."
```

## Quick checks

Run tests:

```bash
PYTHONPATH=src python3 -m unittest discover -s tests -v
```

Run simulated profile example:

```bash
PYTHONPATH=src python3 examples/hypothetical_run.py
```

## Documentation map

- `docs/convergence_first_budget_update.md`
- `docs/profile_studio_overview.md`
- `docs/profile_interpretation_guide.md`
- `docs/query_lab_ab_guide.md`
- `docs/use_cases_routing_and_alignment.md`
- `docs/operations_ingestion_and_history.md`
- `docs/examples_end_to_end_workflows.md`
